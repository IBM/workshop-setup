{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Workshop Setup \u00b6 This repository holds reusable setup instructions for a diverse set of hands-on labs and tutorials. Common Setups \u00b6 Some of the common setup instructions are: New IBM Cloud Upgrade IBM Cloud Account to Pay-As-You-Go Log into IBM Cloud Account Labs at CognitiveClass.ai Free Kubernetes Cluster Grant Cluster Permissions Connect to RedHat OpenShift Kubernetes Service (ROKS) IBM Container Registry (ICR) All Setups \u00b6 Calico IBM Cloud Shell Labs at CognitiveClass.ai Free Kubernetes Cluster Grant Cluster Permissions Helm v3 Log into IBM Cloud Account Jenkins MkDocs New IBM Cloud Upgrade IBM Cloud account to Pay-As-You-Go Connect to RedHat OpenShift Kubernetes Service (ROKS) Install Red Hat OpenShift Pipelines Operator Source-to-Image (S2I)","title":"About the workshop"},{"location":"#workshop-setup","text":"This repository holds reusable setup instructions for a diverse set of hands-on labs and tutorials.","title":"Workshop Setup"},{"location":"#common-setups","text":"Some of the common setup instructions are: New IBM Cloud Upgrade IBM Cloud Account to Pay-As-You-Go Log into IBM Cloud Account Labs at CognitiveClass.ai Free Kubernetes Cluster Grant Cluster Permissions Connect to RedHat OpenShift Kubernetes Service (ROKS) IBM Container Registry (ICR)","title":"Common Setups"},{"location":"#all-setups","text":"Calico IBM Cloud Shell Labs at CognitiveClass.ai Free Kubernetes Cluster Grant Cluster Permissions Helm v3 Log into IBM Cloud Account Jenkins MkDocs New IBM Cloud Upgrade IBM Cloud account to Pay-As-You-Go Connect to RedHat OpenShift Kubernetes Service (ROKS) Install Red Hat OpenShift Pipelines Operator Source-to-Image (S2I)","title":"All Setups"},{"location":"CALICO/","text":"Calico \u00b6 IBM Cloud Kubernetes Service (IKS) \u00b6 Calico is installed by default on IKS. To install the calicoctl client follow the instructions below. Connect to your Kubernetes cluster to start using the calicoctl . If you need help to setup your free IBM Cloud Kubernetes Service (IKS) cluster, go here , or to setup your RedHat OpenShift Kubernetes Service (ROKS), go here . calicoctl \u00b6 The following commands will install the calicoctl client in the browser-based terminal environment at CognitiveClass.ai . If you need help setting up the client terminal at CognitiveClass.ai, follow the instructions here . mkdir calico wget https://github.com/projectcalico/calicoctl/releases/download/v3.17.1/calicoctl -P ./calico chmod +x calico/calicoctl echo \"export PATH=$(pwd)/calico/:$PATH\" > $HOME/.bash_profile source $HOME/.bash_profile calicoctl version Client Version: v3.17.1 Git commit: 8871aca3 Unable to retrieve Cluster Version or Type: connection is unauthorized: clusterinformations.crd.projectcalico.org \"default\" is forbidden: User \"system:serviceaccount:sn-labs-remkohdev:remkohdev\" cannot get resource \"clusterinformations\" in API group \"crd.projectcalico.org\" at the cluster scope As kubectl Plugin \u00b6 To install the calicoctl as a plugin to the kubectl client, run the following commands, mkdir calico curl -o ./calico/kubectl-calico -L https://github.com/projectcalico/calicoctl/releases/download/v3.17.1/calicoctl chmod +x ./calico/kubectl-calico echo \"export PATH=$(pwd)/calico/:$PATH\" > $HOME/.bash_profile source $HOME/.bash_profile kubectl calico -h","title":"Calico"},{"location":"CALICO/#calico","text":"","title":"Calico"},{"location":"CALICO/#ibm-cloud-kubernetes-service-iks","text":"Calico is installed by default on IKS. To install the calicoctl client follow the instructions below. Connect to your Kubernetes cluster to start using the calicoctl . If you need help to setup your free IBM Cloud Kubernetes Service (IKS) cluster, go here , or to setup your RedHat OpenShift Kubernetes Service (ROKS), go here .","title":"IBM Cloud Kubernetes Service (IKS)"},{"location":"CALICO/#calicoctl","text":"The following commands will install the calicoctl client in the browser-based terminal environment at CognitiveClass.ai . If you need help setting up the client terminal at CognitiveClass.ai, follow the instructions here . mkdir calico wget https://github.com/projectcalico/calicoctl/releases/download/v3.17.1/calicoctl -P ./calico chmod +x calico/calicoctl echo \"export PATH=$(pwd)/calico/:$PATH\" > $HOME/.bash_profile source $HOME/.bash_profile calicoctl version Client Version: v3.17.1 Git commit: 8871aca3 Unable to retrieve Cluster Version or Type: connection is unauthorized: clusterinformations.crd.projectcalico.org \"default\" is forbidden: User \"system:serviceaccount:sn-labs-remkohdev:remkohdev\" cannot get resource \"clusterinformations\" in API group \"crd.projectcalico.org\" at the cluster scope","title":"calicoctl"},{"location":"CALICO/#as-kubectl-plugin","text":"To install the calicoctl as a plugin to the kubectl client, run the following commands, mkdir calico curl -o ./calico/kubectl-calico -L https://github.com/projectcalico/calicoctl/releases/download/v3.17.1/calicoctl chmod +x ./calico/kubectl-calico echo \"export PATH=$(pwd)/calico/:$PATH\" > $HOME/.bash_profile source $HOME/.bash_profile kubectl calico -h","title":"As kubectl Plugin"},{"location":"CLOUDSHELL/","text":"IBM Cloud Shell \u00b6 You can access the IBM Cloud Shell directly at IBM Cloud Shell .","title":"IBM Cloud Shell"},{"location":"CLOUDSHELL/#ibm-cloud-shell","text":"You can access the IBM Cloud Shell directly at IBM Cloud Shell .","title":"IBM Cloud Shell"},{"location":"COGNITIVECLASS/","text":"CognitiveClass.ai \u00b6 Access CognitiveClass.ai \u00b6 If you have already registered your account, you can access the lab environment at https://labs.cognitiveclass.ai and login. Navigate to https://labs.cognitiveclass.ai/register , Create a new account with your existing IBM Id. Alternative, you can choose to use a Social login (LinkedIn, Google, Github or Facebook), or for using your email account click the Cognitive Class button, Click Create an Account , Fill in your Email, Full Name, Public Username and password, click on the check boxes next to the Privacy Notice and Terms of Service to accept them. Then click on Create Account . You will then be taken to a page with a list of sandbox environments. Click on the option for Theia - Cloud IDE (With OpenShift) Wait a few minutes while your environment is created. You will be taken to a blank editor page once your environment is ready. What we really need is access to the terminal. Click on the Terminal tab near the top of the page and select New Terminal You can then click and drag the top of the terminal section upwards to make the terminal section bigger.","title":"Labs at CognitiveClass.ai"},{"location":"COGNITIVECLASS/#cognitiveclassai","text":"","title":"CognitiveClass.ai"},{"location":"COGNITIVECLASS/#access-cognitiveclassai","text":"If you have already registered your account, you can access the lab environment at https://labs.cognitiveclass.ai and login. Navigate to https://labs.cognitiveclass.ai/register , Create a new account with your existing IBM Id. Alternative, you can choose to use a Social login (LinkedIn, Google, Github or Facebook), or for using your email account click the Cognitive Class button, Click Create an Account , Fill in your Email, Full Name, Public Username and password, click on the check boxes next to the Privacy Notice and Terms of Service to accept them. Then click on Create Account . You will then be taken to a page with a list of sandbox environments. Click on the option for Theia - Cloud IDE (With OpenShift) Wait a few minutes while your environment is created. You will be taken to a blank editor page once your environment is ready. What we really need is access to the terminal. Click on the Terminal tab near the top of the page and select New Terminal You can then click and drag the top of the terminal section upwards to make the terminal section bigger.","title":"Access CognitiveClass.ai"},{"location":"FREEIKSCLUSTER/","text":"Create Free Kubernetes Cluster \u00b6 Prerequirements \u00b6 Free IBM Cloud account, to create a new IBM Cloud account go here . Free IBM Cloud Pay-As-You-Go account, to upgrade to a Pay-As-You-Go account go here IBM Cloud CLI with the Kubernetes Service plugin, see the IBM Cloud CLI Getting Started , or use a pre-installed client environment like the Labs environment at CognitiveClass, CognitiveLabs.ai account, to access a client terminal at CognitiveLabs.ai, go here . Using UI \u00b6 Log in to IBM Cloud , Go to the Services Catalog , Filter the services by Kubernetes , Click the Kubernetes Service tile, Or go to the Create Kubernetes Service page directly, Configure the Kubernetes cluster as follows: For Pricing plan select Free . The page options will reload, leaving the default Kubernetes version as your only option, At the time of writing, the default Kubernetes version was set to 1.18.13 , Under Orchestration service , edit the Cluster name to a globally unique name, I recommend to follow a format like username-iks118-1n-cluster1 , where iks118 represents your Kubernetes version, 1n the number of worker nodes, and cluster1 represents your cluster number, in case you have more than 1 cluster. For Resource Group keep the Default resource group, unless you have created a new resource group and want to use your own resource group, Click Create to initiate the create cluster request, You will be forwarded to the Access details for the new cluster, Using CLI \u00b6 To create a free Kubernetes Service, you need to be logged in to a free IBM Cloud Pay-As-You-Go account. IBMID=<your ibm id email> USERNAME=<your short username> KS_CLUSTER_NAME=$USERNAME-iks118-1n-cluster1 KS_ZONE=dal10 KS_VERSION=1.18 KS_FLAVOR=u3c.2x4 KS_WORKERS=1 KS_PROVIDER=classic ibmcloud ks zone ls --provider $KS_PROVIDER ibmcloud ks flavors --zone $KS_ZONE --provider $KS_PROVIDER ibmcloud ks versions ibmcloud login -u $IBMID ibmcloud ks cluster create $KS_PROVIDER --name $KS_CLUSTER_NAME --zone $KS_ZONE --version $KS_VERSION --flavor $KS_FLAVOR --workers $KS_WORKERS The response should display similar output as, $ ibmcloud ks cluster create $KS_PROVIDER --name $KS_CLUSTER_NAME --zone $KS_ZONE --version $KS_VERSION --flavor $KS_FLAVOR --workers $KS_WORKERS Creating cluster... OK Cluster created with ID bvlntf2d0fe4l9hnres0 Retrieve details of the new cluster, ibmcloud ks cluster get --cluster $KS_CLUSTER_NAME --output json","title":"Create Free Kubernetes Cluster"},{"location":"FREEIKSCLUSTER/#create-free-kubernetes-cluster","text":"","title":"Create Free Kubernetes Cluster"},{"location":"FREEIKSCLUSTER/#prerequirements","text":"Free IBM Cloud account, to create a new IBM Cloud account go here . Free IBM Cloud Pay-As-You-Go account, to upgrade to a Pay-As-You-Go account go here IBM Cloud CLI with the Kubernetes Service plugin, see the IBM Cloud CLI Getting Started , or use a pre-installed client environment like the Labs environment at CognitiveClass, CognitiveLabs.ai account, to access a client terminal at CognitiveLabs.ai, go here .","title":"Prerequirements"},{"location":"FREEIKSCLUSTER/#using-ui","text":"Log in to IBM Cloud , Go to the Services Catalog , Filter the services by Kubernetes , Click the Kubernetes Service tile, Or go to the Create Kubernetes Service page directly, Configure the Kubernetes cluster as follows: For Pricing plan select Free . The page options will reload, leaving the default Kubernetes version as your only option, At the time of writing, the default Kubernetes version was set to 1.18.13 , Under Orchestration service , edit the Cluster name to a globally unique name, I recommend to follow a format like username-iks118-1n-cluster1 , where iks118 represents your Kubernetes version, 1n the number of worker nodes, and cluster1 represents your cluster number, in case you have more than 1 cluster. For Resource Group keep the Default resource group, unless you have created a new resource group and want to use your own resource group, Click Create to initiate the create cluster request, You will be forwarded to the Access details for the new cluster,","title":"Using UI"},{"location":"FREEIKSCLUSTER/#using-cli","text":"To create a free Kubernetes Service, you need to be logged in to a free IBM Cloud Pay-As-You-Go account. IBMID=<your ibm id email> USERNAME=<your short username> KS_CLUSTER_NAME=$USERNAME-iks118-1n-cluster1 KS_ZONE=dal10 KS_VERSION=1.18 KS_FLAVOR=u3c.2x4 KS_WORKERS=1 KS_PROVIDER=classic ibmcloud ks zone ls --provider $KS_PROVIDER ibmcloud ks flavors --zone $KS_ZONE --provider $KS_PROVIDER ibmcloud ks versions ibmcloud login -u $IBMID ibmcloud ks cluster create $KS_PROVIDER --name $KS_CLUSTER_NAME --zone $KS_ZONE --version $KS_VERSION --flavor $KS_FLAVOR --workers $KS_WORKERS The response should display similar output as, $ ibmcloud ks cluster create $KS_PROVIDER --name $KS_CLUSTER_NAME --zone $KS_ZONE --version $KS_VERSION --flavor $KS_FLAVOR --workers $KS_WORKERS Creating cluster... OK Cluster created with ID bvlntf2d0fe4l9hnres0 Retrieve details of the new cluster, ibmcloud ks cluster get --cluster $KS_CLUSTER_NAME --output json","title":"Using CLI"},{"location":"GRANTCLUSTER/","text":"Grant Cluster \u00b6 IBM Kubernetes Service (IKS) and RedHat OpenShift Kubernetes Service (ROKS) \u00b6 The grant cluster method to get access to a Kubernetes cluster will assign access permissions to a cluster or namespace in a cluster that was created prior to the request. Creating a cluster and provisioning the VMs and other resources and deploying the tools may take up to 15 minutes and longer if queued. Permissioning access to an existing cluster in contrast happens in 1 or 2 minutes depending on the number of concurrent requests. You need an IBM Cloud account to access your cluster, If you do not have an IBM Cloud account yet, register at https://cloud.ibm.com/registration , Or find instructions to create a new IBM Cloud account here , To grant a cluster, You need to be given a URL to submit your grant cluster request, Open the URL to grant a cluster, e.g. https://<workshop>.mybluemix.net , The grant cluster URL should open the following page, Complete the form using the lab key given to you by the instructor and your IBM Id to access your IBM Cloud account. Before you can access the new account, you will need to accept the invitation that was sent to your email. In a new tab, log in to your email that you used to sign up for IBM Cloud and look for an email from IBM Cloud [no-reply@cloud.ibm.com] and click on Join Now You should then be taken to a new page that has a form with prefilled information from your IBM Cloud account. Ensure that the information is correct and then click on the Join Account button. You can then go back to the success page of the grant-cluster application and follow the instructions to log into the IBM Cloud account. Instructions will ask to Log in to this IBM Cloud account When you click the link to log in to the IBM Cloud account, the IBM Cloud overview page will load with an overview of all resources on the account. In the top right, you will see an active account listed. The active account should be the account on which the cluster is created, which is not your personal account. Click the account dropdown if you need to change the active account. Navigate to Clusters, And select the cluster assigned to you... Details for your cluster will load, Go to the Access menu item in the left navigation column, Follow the instructions to access your cluster from the client, Optionally, you can use the IBM Cloud Shell at https://shell.cloud.ibm.com/ to check access. The cloud shell is attached to your IBM Id. It might take a few moments to create the instance and a new session,","title":"Grant Cluster Permissions"},{"location":"GRANTCLUSTER/#grant-cluster","text":"","title":"Grant Cluster"},{"location":"GRANTCLUSTER/#ibm-kubernetes-service-iks-and-redhat-openshift-kubernetes-service-roks","text":"The grant cluster method to get access to a Kubernetes cluster will assign access permissions to a cluster or namespace in a cluster that was created prior to the request. Creating a cluster and provisioning the VMs and other resources and deploying the tools may take up to 15 minutes and longer if queued. Permissioning access to an existing cluster in contrast happens in 1 or 2 minutes depending on the number of concurrent requests. You need an IBM Cloud account to access your cluster, If you do not have an IBM Cloud account yet, register at https://cloud.ibm.com/registration , Or find instructions to create a new IBM Cloud account here , To grant a cluster, You need to be given a URL to submit your grant cluster request, Open the URL to grant a cluster, e.g. https://<workshop>.mybluemix.net , The grant cluster URL should open the following page, Complete the form using the lab key given to you by the instructor and your IBM Id to access your IBM Cloud account. Before you can access the new account, you will need to accept the invitation that was sent to your email. In a new tab, log in to your email that you used to sign up for IBM Cloud and look for an email from IBM Cloud [no-reply@cloud.ibm.com] and click on Join Now You should then be taken to a new page that has a form with prefilled information from your IBM Cloud account. Ensure that the information is correct and then click on the Join Account button. You can then go back to the success page of the grant-cluster application and follow the instructions to log into the IBM Cloud account. Instructions will ask to Log in to this IBM Cloud account When you click the link to log in to the IBM Cloud account, the IBM Cloud overview page will load with an overview of all resources on the account. In the top right, you will see an active account listed. The active account should be the account on which the cluster is created, which is not your personal account. Click the account dropdown if you need to change the active account. Navigate to Clusters, And select the cluster assigned to you... Details for your cluster will load, Go to the Access menu item in the left navigation column, Follow the instructions to access your cluster from the client, Optionally, you can use the IBM Cloud Shell at https://shell.cloud.ibm.com/ to check access. The cloud shell is attached to your IBM Id. It might take a few moments to create the instance and a new session,","title":"IBM Kubernetes Service (IKS) and RedHat OpenShift Kubernetes Service (ROKS)"},{"location":"HELM/","text":"Helm v3 \u00b6 Refer to the Helm install docs for more details. To install Helm v3, run the following commands, In the Cloud Shell , download and unzip Helm v3.2. cd $HOME wget https://get.helm.sh/helm-v3.2.0-linux-amd64.tar.gz tar -zxvf helm-v3.2.0-linux-amd64.tar.gz Make Helm v3 CLI available in your PATH environment variable. echo 'export PATH=$HOME/linux-amd64:$PATH' > $HOME/.bash_profile source $HOME/.bash_profile Verify Helm v3 installation. helm version --short outputs, $ helm version --short v3.2.0+ge11b7ce","title":"Helm v3"},{"location":"HELM/#helm-v3","text":"Refer to the Helm install docs for more details. To install Helm v3, run the following commands, In the Cloud Shell , download and unzip Helm v3.2. cd $HOME wget https://get.helm.sh/helm-v3.2.0-linux-amd64.tar.gz tar -zxvf helm-v3.2.0-linux-amd64.tar.gz Make Helm v3 CLI available in your PATH environment variable. echo 'export PATH=$HOME/linux-amd64:$PATH' > $HOME/.bash_profile source $HOME/.bash_profile Verify Helm v3 installation. helm version --short outputs, $ helm version --short v3.2.0+ge11b7ce","title":"Helm v3"},{"location":"IBMCLOUD/","text":"Log into IBM Cloud Account \u00b6 If you already have an existing IBM Cloud account, follow the instructions below to log into your IBM Cloud account. To register for a new IBM Cloud account, go here . Open a web browser to open the IBM Cloud console at https://cloud.ibm.com/login . When prompted, enter your IBM Id (the email ID you used to create the account above) followed by your password to login. Click Continue , When prompted for your password, enter your password, Click Log in , When successfully authenticated, the IBM Cloud Dashboard will load,","title":"Log into IBM Cloud Account"},{"location":"IBMCLOUD/#log-into-ibm-cloud-account","text":"If you already have an existing IBM Cloud account, follow the instructions below to log into your IBM Cloud account. To register for a new IBM Cloud account, go here . Open a web browser to open the IBM Cloud console at https://cloud.ibm.com/login . When prompted, enter your IBM Id (the email ID you used to create the account above) followed by your password to login. Click Continue , When prompted for your password, enter your password, Click Log in , When successfully authenticated, the IBM Cloud Dashboard will load,","title":"Log into IBM Cloud Account"},{"location":"JENKINS/","text":"Jenkins \u00b6 Pre-requirements \u00b6 OpenShift 4.x cluster Setup \u00b6 From the IBM Cloud cluster dashboard, click the OpenShift web console button, First we need to create a new project named jenkins to deploy the Jenkins service to, From the terminal, oc new-project jenkins outputs, $ oc new-project jenkins Now using project \"jenkins\" on server \"https://c107-e.us-south.containers.cloud.ibm.com:31608\". Or in the Openshift web console, go to Home > Projects , Click Create Project For Name enter jenkins , for Display Name enter jenkins , and for Description enter jenkins , Click Create , Go to Operators > OperatorHub , For Filter by keyword enter Jenkins , Select the Jenkins Operator provided by Red Hat , labeled community , Click Continue to Show Community Operator , Review the operator information, and click Install , In the Install Operator window, in the Update Channel section, select alpha under Update Channel , choose A specific namespace in the cluster and in the Installed Namespace section, select the project jenkins from the dropdown, select Automatic under Approval Strategy , Click Install , The Installed Operators page will load, wait until the Jenkins Operator has a Status of Succeeded , Click the installed operator linked Name of Jenkins Operator , In the Provided APIs section, click the Create Instance link in the Jenkins panel, In the Create Jenkins window, select Form View or YAML View for the new Jenkins instance, change the metadata.name to my-jenkins , accept all other specifications, Click Create , Go to Networking > Routes , and look for a new Route jenkins-my-jenkins , Click the link for jenkins-my-jenkins route in the Location column, A route to your Jenkins instance opens in a new browser window or tab, If your page loads with a Application is not available warning, your Jenkins instance is still being deployed and you need to wait a little longer, keep trying until the Jenkins page loads, You can see the progress of the Jenkins startup, by browsing to the Pods of the Deployment of the Jenkins instance that is being created, Click Log in with OpenShift , Click Allow selected permissions , Welcome to Jenkins ! Configure Jenkins Go to Jenkins > Manage Jenkins > Global Tool Configuration, Go to the Maven section, Click Maven Installations , If no Maven installer is configured, click Add Maven , Configure the Name to be maven , check the option Install automatically and select version 3.6.3 , Click Save,","title":"Jenkins"},{"location":"JENKINS/#jenkins","text":"","title":"Jenkins"},{"location":"JENKINS/#pre-requirements","text":"OpenShift 4.x cluster","title":"Pre-requirements"},{"location":"JENKINS/#setup","text":"From the IBM Cloud cluster dashboard, click the OpenShift web console button, First we need to create a new project named jenkins to deploy the Jenkins service to, From the terminal, oc new-project jenkins outputs, $ oc new-project jenkins Now using project \"jenkins\" on server \"https://c107-e.us-south.containers.cloud.ibm.com:31608\". Or in the Openshift web console, go to Home > Projects , Click Create Project For Name enter jenkins , for Display Name enter jenkins , and for Description enter jenkins , Click Create , Go to Operators > OperatorHub , For Filter by keyword enter Jenkins , Select the Jenkins Operator provided by Red Hat , labeled community , Click Continue to Show Community Operator , Review the operator information, and click Install , In the Install Operator window, in the Update Channel section, select alpha under Update Channel , choose A specific namespace in the cluster and in the Installed Namespace section, select the project jenkins from the dropdown, select Automatic under Approval Strategy , Click Install , The Installed Operators page will load, wait until the Jenkins Operator has a Status of Succeeded , Click the installed operator linked Name of Jenkins Operator , In the Provided APIs section, click the Create Instance link in the Jenkins panel, In the Create Jenkins window, select Form View or YAML View for the new Jenkins instance, change the metadata.name to my-jenkins , accept all other specifications, Click Create , Go to Networking > Routes , and look for a new Route jenkins-my-jenkins , Click the link for jenkins-my-jenkins route in the Location column, A route to your Jenkins instance opens in a new browser window or tab, If your page loads with a Application is not available warning, your Jenkins instance is still being deployed and you need to wait a little longer, keep trying until the Jenkins page loads, You can see the progress of the Jenkins startup, by browsing to the Pods of the Deployment of the Jenkins instance that is being created, Click Log in with OpenShift , Click Allow selected permissions , Welcome to Jenkins ! Configure Jenkins Go to Jenkins > Manage Jenkins > Global Tool Configuration, Go to the Maven section, Click Maven Installations , If no Maven installer is configured, click Add Maven , Configure the Name to be maven , check the option Install automatically and select version 3.6.3 , Click Save,","title":"Setup"},{"location":"MKDOCS/","text":"MkDocs \u00b6 Installation \u00b6 Go to the Installation instructions for MkDocs, alias python=python3 python --version alias pip=pip3 pip --version pip install --upgrade pip pip install mkdocs mkdocs --version To install Material for MkDocs go to the Getting Started instructions, pip install mkdocs-material In the repository root directory, add a new ~/README.md file, this is the landing page for the Github repository different from the MkDocs landing page. MkDocs assumes its root to be the docs folder. vi README.md Migration \u00b6 Get repository, ORG=<github_org> REPO=<repository> git clone https://github.com/$ORG/$REPO.git cd $REPO When converting an existing repository from Gitbook, rename workshop to docs , mv workshop docs For a repository without Gitbook support, create a new directory docs , mkdir docs When converting from Gitbook, edit .gitbook.yaml and change workshop to docs references, sed -i \"\" 's/workshop/docs/' .gitbook.yaml Skip this step for repositories with a docs/README.md file present! If no file docs/README.md exists, add one. The docs/README.md is the landing page for the MkDocs documentation, cat > docs/README.md <<EOF # $REPO # # About EOF Create a new file .github/workflows/ci.yml to configure a Github action, mkdir -p .github/workflows wget -O .github/workflows/ci.yml https://raw.githubusercontent.com/IBM/workshop-setup/master/.github/workflows/ci.yml In the root folder of your project, create a new file ~/mkdocs.yml and add the following content to the new file, cat > mkdocs.yml <<EOF # Project information site_name: <SITE_NAME> site_url: https://ibm.github.io/<REPO_NAME> site_author: IBM Developer # Repository repo_name: <REPO_NAME> repo_url: https://github.com/ibm/<REPO_NAME> edit_uri: edit/master/docs # Navigation nav: - Welcome: - About the workshop: README.md - Workshop: - Lab 1: lab1.md - Lab 2: lab2.md - References: - Additional resources: references/RESOURCES.md - Contributors: references/CONTRIBUTORS.md # # DO NOT CHANGE BELOW THIS LINE # Copyright copyright: Copyright &copy; 2020 IBM Developer # Theme theme: name: material font: text: IBM Plex Sans code: IBM Plex Mono icon: logo: material/library features: - navigation.tabs # - navigation.instant palette: scheme: default primary: blue accent: blue # Plugins plugins: - search # Customization extra: social: - icon: fontawesome/brands/github link: https://github.com/ibm - icon: fontawesome/brands/twitter link: https://twitter.com/ibmdeveloper - icon: fontawesome/brands/linkedin link: https://www.linkedin.com/company/ibm/ - icon: fontawesome/brands/youtube link: https://www.youtube.com/user/developerworks - icon: fontawesome/brands/dev link: https://dev.to/ibmdeveloper # Extensions markdown_extensions: - abbr - admonition - attr_list - def_list - footnotes - meta - toc: permalink: true - pymdownx.arithmatex: generic: true - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_index: !!python/name:materialx.emoji.twemoji emoji_generator: !!python/name:materialx.emoji.to_svg - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.keys - pymdownx.mark - pymdownx.smartsymbols - pymdownx.snippets: check_paths: true - pymdownx.superfences: custom_fences: - name: mermaid class: mermaid format: !!python/name:pymdownx.superfences.fence_code_format - pymdownx.tabbed - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde EOF Edit the above file mkdocs.yml , change: <SITE_NAME> <REPO_NAME> when converting from Gitbook: copy the navigation links from workshop/SUMMARY.md to the Navigation section and copy-edit the links for the navigation, sed -i \"\" \"s/<SITE_NAME>/$REPO/\" mkdocs.yml sed -i \"\" \"s/<REPO_NAME>/$REPO/\" mkdocs.yml The above navigation example includes two example items, you need to add the files docs/lab1.md and docs/lab2.md to enable the examples, echo '# Lab One' > docs/lab1.md echo '# Lab Two' > docs/lab2.md But for existing content, you need to overwrite the navigation. If your repository has an existing Gitbook, you can copy the navigation in the docs/SUMMARY.md file, to the # Navigation nav: section in mkdocs.yml , Add a file .gitignore with the following exceptions, echo \"\\n# MkDocs\\nsite/\\n\" >> .gitignore Add a new file ~/markdownlint.json with the following rule, cat > markdownlint.json <<EOF { \"line-length\": false } EOF Add a new file .markdownlintignore , when converting from Gitbook, add the following exceptions, cat > .markdownlintignore <<EOF workshop/SUMMARY.md workshop/README.md EOF When migrating from Gitbook , if a .travis.yml file already exists, replace reference to workshop by docs , sed -i \"\" 's/workshop/docs/' .travis.yml Add a new file .travis.yml , cat > .travis.yml <<EOF --- language: node_js node_js: 10 before_script: - npm install markdownlint-cli script: - markdownlint -c .markdownlint.json docs EOF If you don't have a LICENSE file yet, download the LICENSE file, wget -O LICENSE https://raw.githubusercontent.com/IBM/workshop-setup/master/LICENSE Test the docs locally with the command mkdocs serve , Review the WARNING output, fix where necessary, Create a new repository in Github, Initialize the local repository, add all files, commit, add the remote, and push changes, echo \"# test1\" >> README.md git init git add . git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/remkohdev/test1.git git push -u origin main Github pages use a branch called gh-pages , this branch is automatically created if it does not exist by the Github action that is defined in the .github/workflows/ci.yml , Github also needs to resolve the domain name and URI to the repository, and point it to the correct branch of the Github page for the repo. To configure this, in your repo, go to Settings, scroll down to GitHub Pages section and from the Source dropdown, select the branch gh-pages , accept the default /root and click Save . Your MkDocs branch should now be live. Whenever you push changes to your main branch, the Github action to deploy MkDocs will be triggered again, Add an update to your README.md, vi README.md Push changes, git add . git commit -m \"second commit\" git push Check your actions at https://github.com/<ORG>/<REPO>/actions . Export to PDF \u00b6 There are several plugins to export mkdocs to PDF, mkdocs-pdf-export , MkPdf , Install the plugin, Enable the plugin by adding the plugin line to the plugins list in mkdocs.yml , to use the pdf-export plugin, add, plugins: - pdf-export: verbose: true media_type: print enabled_if_env: ENABLE_PDF_EXPORT combined: true Run mkdocs build , which will create a pdf directory with the combined PDF, e.g. to run pdf-export , ENABLE_PDF_EXPORT=1 mkdocs build","title":"MkDocs"},{"location":"MKDOCS/#mkdocs","text":"","title":"MkDocs"},{"location":"MKDOCS/#installation","text":"Go to the Installation instructions for MkDocs, alias python=python3 python --version alias pip=pip3 pip --version pip install --upgrade pip pip install mkdocs mkdocs --version To install Material for MkDocs go to the Getting Started instructions, pip install mkdocs-material In the repository root directory, add a new ~/README.md file, this is the landing page for the Github repository different from the MkDocs landing page. MkDocs assumes its root to be the docs folder. vi README.md","title":"Installation"},{"location":"MKDOCS/#migration","text":"Get repository, ORG=<github_org> REPO=<repository> git clone https://github.com/$ORG/$REPO.git cd $REPO When converting an existing repository from Gitbook, rename workshop to docs , mv workshop docs For a repository without Gitbook support, create a new directory docs , mkdir docs When converting from Gitbook, edit .gitbook.yaml and change workshop to docs references, sed -i \"\" 's/workshop/docs/' .gitbook.yaml Skip this step for repositories with a docs/README.md file present! If no file docs/README.md exists, add one. The docs/README.md is the landing page for the MkDocs documentation, cat > docs/README.md <<EOF # $REPO # # About EOF Create a new file .github/workflows/ci.yml to configure a Github action, mkdir -p .github/workflows wget -O .github/workflows/ci.yml https://raw.githubusercontent.com/IBM/workshop-setup/master/.github/workflows/ci.yml In the root folder of your project, create a new file ~/mkdocs.yml and add the following content to the new file, cat > mkdocs.yml <<EOF # Project information site_name: <SITE_NAME> site_url: https://ibm.github.io/<REPO_NAME> site_author: IBM Developer # Repository repo_name: <REPO_NAME> repo_url: https://github.com/ibm/<REPO_NAME> edit_uri: edit/master/docs # Navigation nav: - Welcome: - About the workshop: README.md - Workshop: - Lab 1: lab1.md - Lab 2: lab2.md - References: - Additional resources: references/RESOURCES.md - Contributors: references/CONTRIBUTORS.md # # DO NOT CHANGE BELOW THIS LINE # Copyright copyright: Copyright &copy; 2020 IBM Developer # Theme theme: name: material font: text: IBM Plex Sans code: IBM Plex Mono icon: logo: material/library features: - navigation.tabs # - navigation.instant palette: scheme: default primary: blue accent: blue # Plugins plugins: - search # Customization extra: social: - icon: fontawesome/brands/github link: https://github.com/ibm - icon: fontawesome/brands/twitter link: https://twitter.com/ibmdeveloper - icon: fontawesome/brands/linkedin link: https://www.linkedin.com/company/ibm/ - icon: fontawesome/brands/youtube link: https://www.youtube.com/user/developerworks - icon: fontawesome/brands/dev link: https://dev.to/ibmdeveloper # Extensions markdown_extensions: - abbr - admonition - attr_list - def_list - footnotes - meta - toc: permalink: true - pymdownx.arithmatex: generic: true - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_index: !!python/name:materialx.emoji.twemoji emoji_generator: !!python/name:materialx.emoji.to_svg - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.keys - pymdownx.mark - pymdownx.smartsymbols - pymdownx.snippets: check_paths: true - pymdownx.superfences: custom_fences: - name: mermaid class: mermaid format: !!python/name:pymdownx.superfences.fence_code_format - pymdownx.tabbed - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde EOF Edit the above file mkdocs.yml , change: <SITE_NAME> <REPO_NAME> when converting from Gitbook: copy the navigation links from workshop/SUMMARY.md to the Navigation section and copy-edit the links for the navigation, sed -i \"\" \"s/<SITE_NAME>/$REPO/\" mkdocs.yml sed -i \"\" \"s/<REPO_NAME>/$REPO/\" mkdocs.yml The above navigation example includes two example items, you need to add the files docs/lab1.md and docs/lab2.md to enable the examples, echo '# Lab One' > docs/lab1.md echo '# Lab Two' > docs/lab2.md But for existing content, you need to overwrite the navigation. If your repository has an existing Gitbook, you can copy the navigation in the docs/SUMMARY.md file, to the # Navigation nav: section in mkdocs.yml , Add a file .gitignore with the following exceptions, echo \"\\n# MkDocs\\nsite/\\n\" >> .gitignore Add a new file ~/markdownlint.json with the following rule, cat > markdownlint.json <<EOF { \"line-length\": false } EOF Add a new file .markdownlintignore , when converting from Gitbook, add the following exceptions, cat > .markdownlintignore <<EOF workshop/SUMMARY.md workshop/README.md EOF When migrating from Gitbook , if a .travis.yml file already exists, replace reference to workshop by docs , sed -i \"\" 's/workshop/docs/' .travis.yml Add a new file .travis.yml , cat > .travis.yml <<EOF --- language: node_js node_js: 10 before_script: - npm install markdownlint-cli script: - markdownlint -c .markdownlint.json docs EOF If you don't have a LICENSE file yet, download the LICENSE file, wget -O LICENSE https://raw.githubusercontent.com/IBM/workshop-setup/master/LICENSE Test the docs locally with the command mkdocs serve , Review the WARNING output, fix where necessary, Create a new repository in Github, Initialize the local repository, add all files, commit, add the remote, and push changes, echo \"# test1\" >> README.md git init git add . git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/remkohdev/test1.git git push -u origin main Github pages use a branch called gh-pages , this branch is automatically created if it does not exist by the Github action that is defined in the .github/workflows/ci.yml , Github also needs to resolve the domain name and URI to the repository, and point it to the correct branch of the Github page for the repo. To configure this, in your repo, go to Settings, scroll down to GitHub Pages section and from the Source dropdown, select the branch gh-pages , accept the default /root and click Save . Your MkDocs branch should now be live. Whenever you push changes to your main branch, the Github action to deploy MkDocs will be triggered again, Add an update to your README.md, vi README.md Push changes, git add . git commit -m \"second commit\" git push Check your actions at https://github.com/<ORG>/<REPO>/actions .","title":"Migration"},{"location":"MKDOCS/#export-to-pdf","text":"There are several plugins to export mkdocs to PDF, mkdocs-pdf-export , MkPdf , Install the plugin, Enable the plugin by adding the plugin line to the plugins list in mkdocs.yml , to use the pdf-export plugin, add, plugins: - pdf-export: verbose: true media_type: print enabled_if_env: ENABLE_PDF_EXPORT combined: true Run mkdocs build , which will create a pdf directory with the combined PDF, e.g. to run pdf-export , ENABLE_PDF_EXPORT=1 mkdocs build","title":"Export to PDF"},{"location":"NEWACCOUNT/","text":"Create IBM Cloud ID / Account \u00b6 To create a new account, follow the steps below, Open a web browser and go to the IBM Cloud Sign up page In the Create an account window, enter your company email id and the password you would like to use. Click the Next button. The Verify email section will inform you that a verification code was sent to your email. Switch to your email provider to retrieve the verification code. Then enter the verification code in the Verify email section, and click the Next button. Enter your first name, last name and country in the Personal information section and click the Next button. Click the Create account button. After your account is created, review the IBM Privacy Statement . Then scroll down and click the Proceed button to acknowledge the privacy statement. You are now ready to login to the IBM Cloud. Open a web browser to the IBM Cloud console . If prompted, enter your IBM Id (the email ID you used to create the account above) followed by your password to login. The IBM Cloud dashboard page should load. You have successfully registered a new IBM Cloud account.","title":"New IBM Cloud"},{"location":"NEWACCOUNT/#create-ibm-cloud-id-account","text":"To create a new account, follow the steps below, Open a web browser and go to the IBM Cloud Sign up page In the Create an account window, enter your company email id and the password you would like to use. Click the Next button. The Verify email section will inform you that a verification code was sent to your email. Switch to your email provider to retrieve the verification code. Then enter the verification code in the Verify email section, and click the Next button. Enter your first name, last name and country in the Personal information section and click the Next button. Click the Create account button. After your account is created, review the IBM Privacy Statement . Then scroll down and click the Proceed button to acknowledge the privacy statement. You are now ready to login to the IBM Cloud. Open a web browser to the IBM Cloud console . If prompted, enter your IBM Id (the email ID you used to create the account above) followed by your password to login. The IBM Cloud dashboard page should load. You have successfully registered a new IBM Cloud account.","title":"Create IBM Cloud ID / Account"},{"location":"OPENLABS/","text":"Access OpenShift Cluster at OpenLabs \u00b6 These instructions will walk you through how you can get access to a 2 node OpenShift cluster on IBM Cloud through IBM OpenLabs. This cluster will only be available for 2 hours and then will be deleted. Go to IBM OpenLabs: https://developer.ibm.com/openlabs/openshift Find the lab in the Hands on Labs section called Lab 6: Bring Your Own App You will be asked to sign into IBM Cloud if you aren't already or you can register for a new account. Once you sign in the lab will automatically continue provisioning. You may see messages like Allocating VM and so on. When that is done you should be taken to a new page that has documentation on the left half of the screen along with a terminal environment on the right. If not, click on the Lab 6: Bring Your Own App button again. To access your new OpenShift Cluster, click on the tab on the left side of the page labeled Quick Links and Common Commands From this page you can access the OpenShift Web Console and find instructions on how to log in to the cluster in the terminal with the oc cli tool.","title":"Access OpenShift Cluster at OpenLabs"},{"location":"OPENLABS/#access-openshift-cluster-at-openlabs","text":"These instructions will walk you through how you can get access to a 2 node OpenShift cluster on IBM Cloud through IBM OpenLabs. This cluster will only be available for 2 hours and then will be deleted. Go to IBM OpenLabs: https://developer.ibm.com/openlabs/openshift Find the lab in the Hands on Labs section called Lab 6: Bring Your Own App You will be asked to sign into IBM Cloud if you aren't already or you can register for a new account. Once you sign in the lab will automatically continue provisioning. You may see messages like Allocating VM and so on. When that is done you should be taken to a new page that has documentation on the left half of the screen along with a terminal environment on the right. If not, click on the Lab 6: Bring Your Own App button again. To access your new OpenShift Cluster, click on the tab on the left side of the page labeled Quick Links and Common Commands From this page you can access the OpenShift Web Console and find instructions on how to log in to the cluster in the terminal with the oc cli tool.","title":"Access OpenShift Cluster at OpenLabs"},{"location":"PAYASYOUGO/","text":"Upgrade to Pay-As-You-Go Account \u00b6 Login to your IBM Cloud account , Go to account settings , Click the Add credit card button, to create the Pay-As-You-Go account, which will unlock the full catalog, Select the Account type , choose between Company and Personal . For the setup, I will choose Personal . Click Next , Enter your Billing Information , click Next , Enter your Payment information , click Next , Acknowledge that your card will not be charged, but a $1.00 hold will be placed while authorizing the card, Click Upgrade Account , You will receive $200 credit, in case you want to use paid services, Click Done , Under Account settings you should now see Account Type as Pay-As-You-Go . Go to the IBM Cloud Catalog and filter Free and Lite services . Free and Lite Services \u00b6 At the time of writing this setup 115 free and lite services were listed, among other: Analytics Engine, API Connect, API Gateway, App Connect, App ID, Auto Scale for VPC, Certificate Manager, Cloudant, Code Engine, Container Registry, Continuous Delivery, DB2, Direct Link Connect, Discovery, Event Streams with Kafka, Hyper Protect, LogDNA, Sysdig, IBM Cognos, Internet of Things Platform, Internet Services with CloudFlare, Key Protect, Knowledge Studio, Kubernetes Service, Language Translator, Load Balancer for VPC, Machine Learning, MQ, Natural Language Classifier, Natural Language Understanding, Object Storage, PagerDuty, Schematics with Terraform, Secrets Manager, Secure Gateway, Speech to Text, SQL Query, Object Storage with ANSI SQL, Streaming Analytics, Text to Speech, Tone Analyzer, Toolchain, Twilio, Visual Recognition, Voice Agent with Watson, Watson Assistant, Watson Knowledge Catalog, Watson OpenScale, Watson Studio,","title":"Upgrade IBM Cloud account to Pay-As-You-Go"},{"location":"PAYASYOUGO/#upgrade-to-pay-as-you-go-account","text":"Login to your IBM Cloud account , Go to account settings , Click the Add credit card button, to create the Pay-As-You-Go account, which will unlock the full catalog, Select the Account type , choose between Company and Personal . For the setup, I will choose Personal . Click Next , Enter your Billing Information , click Next , Enter your Payment information , click Next , Acknowledge that your card will not be charged, but a $1.00 hold will be placed while authorizing the card, Click Upgrade Account , You will receive $200 credit, in case you want to use paid services, Click Done , Under Account settings you should now see Account Type as Pay-As-You-Go . Go to the IBM Cloud Catalog and filter Free and Lite services .","title":"Upgrade to Pay-As-You-Go Account"},{"location":"PAYASYOUGO/#free-and-lite-services","text":"At the time of writing this setup 115 free and lite services were listed, among other: Analytics Engine, API Connect, API Gateway, App Connect, App ID, Auto Scale for VPC, Certificate Manager, Cloudant, Code Engine, Container Registry, Continuous Delivery, DB2, Direct Link Connect, Discovery, Event Streams with Kafka, Hyper Protect, LogDNA, Sysdig, IBM Cognos, Internet of Things Platform, Internet Services with CloudFlare, Key Protect, Knowledge Studio, Kubernetes Service, Language Translator, Load Balancer for VPC, Machine Learning, MQ, Natural Language Classifier, Natural Language Understanding, Object Storage, PagerDuty, Schematics with Terraform, Secrets Manager, Secure Gateway, Speech to Text, SQL Query, Object Storage with ANSI SQL, Streaming Analytics, Text to Speech, Tone Analyzer, Toolchain, Twilio, Visual Recognition, Voice Agent with Watson, Watson Assistant, Watson Knowledge Catalog, Watson OpenScale, Watson Studio,","title":"Free and Lite Services"},{"location":"PIPELINES/","text":"Install Red Hat OpenShift Pipelines Operator \u00b6 OpenShift Pipelines is provided as an add-on on top of OpenShift that can be installed via an operator that is available in the OpenShift OperatorHub. To start, make sure you are on the Administrator perspective as shown below: Go to Operators > OperatorHub in the Web Console. You can see the list of available operators for OpenShift provided by Red Hat as well as a community of partners and open-source projects. In the search bar where it says Filter by keyword... , type OpenShift Pipelines to find the Red Hat OpenShift Pipelines Operator : Click on Red Hat OpenShift Pipelines Operator , and then Install : Leave the default settings and click on Install in order to subscribe to the installation and update channels: After clicking Install , you will be taken to the Installed Operators page. Wait until the Red Hat OpenShift Pipelines Operator finishes installation. Click View Operator , Or go to Operators > Installed Operators in the web console, That's all. The operator has installed OpenShift Pipelines on the cluster. To confirm the installation, go to Workloads > Pods and check for tekton-pipelines and tekton-triggers pods with Running state in the openshift-pipelines namespace. If so, openshift-pipelines has been successfully installed on your cluster. Note: this is an updated version for ROKS based on Install OpenShift Pipelines by OpenShift.","title":"Install Red Hat OpenShift Pipelines Operator"},{"location":"PIPELINES/#install-red-hat-openshift-pipelines-operator","text":"OpenShift Pipelines is provided as an add-on on top of OpenShift that can be installed via an operator that is available in the OpenShift OperatorHub. To start, make sure you are on the Administrator perspective as shown below: Go to Operators > OperatorHub in the Web Console. You can see the list of available operators for OpenShift provided by Red Hat as well as a community of partners and open-source projects. In the search bar where it says Filter by keyword... , type OpenShift Pipelines to find the Red Hat OpenShift Pipelines Operator : Click on Red Hat OpenShift Pipelines Operator , and then Install : Leave the default settings and click on Install in order to subscribe to the installation and update channels: After clicking Install , you will be taken to the Installed Operators page. Wait until the Red Hat OpenShift Pipelines Operator finishes installation. Click View Operator , Or go to Operators > Installed Operators in the web console, That's all. The operator has installed OpenShift Pipelines on the cluster. To confirm the installation, go to Workloads > Pods and check for tekton-pipelines and tekton-triggers pods with Running state in the openshift-pipelines namespace. If so, openshift-pipelines has been successfully installed on your cluster. Note: this is an updated version for ROKS based on Install OpenShift Pipelines by OpenShift.","title":"Install Red Hat OpenShift Pipelines Operator"},{"location":"ROKS/","text":"Connect to RedHat OpenShift Kubernetes Service (ROKS) \u00b6 There are several manners to log into your OpenShift cluster on IBM Cloud. For a complete overview see Accessing OpenShift clusters . Shell \u00b6 Most of the labs are run using CLI commands. The IBM Cloud Shell available at https://shell.cloud.ibm.com is preconfigured with the full IBM Cloud CLI and tons of plug-ins and tools that you can use to manage apps, resources, and infrastructure. Login to IBM Cloud \u00b6 Login to IBM Cloud via the UI, Go to https://cloud.ibm.com in your browser and login. Make sure that you are in the correct account#. Note: you may not have access to your OpenShift cluster if you are not in the right account#. Login via the CLI, Login, ibmcloud login [ -sso ] if you know the region in which your cluster is located, target the appropriate region, and target a non-default resource-group, ibmcloud regions ibmcloud resource groups export REGION = <region> export RESOURCE_GROUP = <resource-group> ibmcloud target -r $REGION -g $RESOURCE_GROUP Check your Cluster Status \u00b6 export CLUSTER_NAME = <cluster_name> ibmcloud oc cluster get -c $CLUSTER_NAME Login to OpenShift with an API Key \u00b6 export IBMCLOUD_APIKEY_NAME = <username_roks_apikey> ibmcloud iam api-key-create $IBMCLOUD_APIKEY_NAME export IBMCLOUD_APIKEY = <copy_apikey_value> ibmcloud login --apikey $IBMCLOUD_APIKEY ibmcloud target -r $REGION -g $RESOURCE_GROUP ibmcloud oc cluster config -c $CLUSTER_NAME [ --endpoint private ] ibmcloud oc cluster get -c $CLUSTER_NAME oc login -u apikey -p $IBMCLOUD_APIKEY [ --server = <private_service_endpoint> ] Login to OpenShift as Admin \u00b6 Make sure that you have the Administrator platform access role for the cluster. Go to Manage > Access (IAM), in My user details or selected user details, go to Access Policies > click Assign access, From the CLI, you can now login to your cluster using the --admin flag, ibmcloud oc cluster config -c $CLUSTER_NAME --admin Login to OpenShift with an API Token \u00b6 In a new browser tab, go to https://cloud.ibm.com/kubernetes/clusters?platformType=openshift . Make sure the account holding the cluster is selected, Select your cluster instance and open it. Click OpenShift web console button on the top. Click on your username in the upper right and select Copy Login Command option. Click the Display Token link. Copy the contents of the field Log in with this token to the clipboard. It provides a login command with a valid token for your username. Go to the your shell terminal. Paste the oc login command in the IBM Cloud Shell terminal and run it. Verify you connect to the right cluster. oc get all oc get nodes -o wide Optionally, for convenience, set an environment variable for your cluster name. export CLUSTER_NAME=<your_cluster_name>","title":"Connect to RedHat OpenShift Kubernetes Service (ROKS)"},{"location":"ROKS/#connect-to-redhat-openshift-kubernetes-service-roks","text":"There are several manners to log into your OpenShift cluster on IBM Cloud. For a complete overview see Accessing OpenShift clusters .","title":"Connect to RedHat OpenShift Kubernetes Service (ROKS)"},{"location":"ROKS/#shell","text":"Most of the labs are run using CLI commands. The IBM Cloud Shell available at https://shell.cloud.ibm.com is preconfigured with the full IBM Cloud CLI and tons of plug-ins and tools that you can use to manage apps, resources, and infrastructure.","title":"Shell"},{"location":"ROKS/#login-to-ibm-cloud","text":"Login to IBM Cloud via the UI, Go to https://cloud.ibm.com in your browser and login. Make sure that you are in the correct account#. Note: you may not have access to your OpenShift cluster if you are not in the right account#. Login via the CLI, Login, ibmcloud login [ -sso ] if you know the region in which your cluster is located, target the appropriate region, and target a non-default resource-group, ibmcloud regions ibmcloud resource groups export REGION = <region> export RESOURCE_GROUP = <resource-group> ibmcloud target -r $REGION -g $RESOURCE_GROUP","title":"Login to IBM Cloud"},{"location":"ROKS/#check-your-cluster-status","text":"export CLUSTER_NAME = <cluster_name> ibmcloud oc cluster get -c $CLUSTER_NAME","title":"Check your Cluster Status"},{"location":"ROKS/#login-to-openshift-with-an-api-key","text":"export IBMCLOUD_APIKEY_NAME = <username_roks_apikey> ibmcloud iam api-key-create $IBMCLOUD_APIKEY_NAME export IBMCLOUD_APIKEY = <copy_apikey_value> ibmcloud login --apikey $IBMCLOUD_APIKEY ibmcloud target -r $REGION -g $RESOURCE_GROUP ibmcloud oc cluster config -c $CLUSTER_NAME [ --endpoint private ] ibmcloud oc cluster get -c $CLUSTER_NAME oc login -u apikey -p $IBMCLOUD_APIKEY [ --server = <private_service_endpoint> ]","title":"Login to OpenShift with an API Key"},{"location":"ROKS/#login-to-openshift-as-admin","text":"Make sure that you have the Administrator platform access role for the cluster. Go to Manage > Access (IAM), in My user details or selected user details, go to Access Policies > click Assign access, From the CLI, you can now login to your cluster using the --admin flag, ibmcloud oc cluster config -c $CLUSTER_NAME --admin","title":"Login to OpenShift as Admin"},{"location":"ROKS/#login-to-openshift-with-an-api-token","text":"In a new browser tab, go to https://cloud.ibm.com/kubernetes/clusters?platformType=openshift . Make sure the account holding the cluster is selected, Select your cluster instance and open it. Click OpenShift web console button on the top. Click on your username in the upper right and select Copy Login Command option. Click the Display Token link. Copy the contents of the field Log in with this token to the clipboard. It provides a login command with a valid token for your username. Go to the your shell terminal. Paste the oc login command in the IBM Cloud Shell terminal and run it. Verify you connect to the right cluster. oc get all oc get nodes -o wide Optionally, for convenience, set an environment variable for your cluster name. export CLUSTER_NAME=<your_cluster_name>","title":"Login to OpenShift with an API Token"},{"location":"S2I/","text":"Source-to-Image (S2I) \u00b6 To install s2i CLI tool, Download tar file. curl -s https://api.github.com/repos/openshift/source-to-image/releases/latest \\ | grep browser_download_url \\ | grep linux-amd64 \\ | cut -d '\"' -f 4 \\ | wget -qi - Unzip tar file sudo tar xvf source-to-image*.gz Make s2i CLI accessiblee. sudo mv s2i /usr/local/bin verify s2i version With that done, you can start the lab.","title":"Source-to-Image (S2I)"},{"location":"S2I/#source-to-image-s2i","text":"To install s2i CLI tool, Download tar file. curl -s https://api.github.com/repos/openshift/source-to-image/releases/latest \\ | grep browser_download_url \\ | grep linux-amd64 \\ | cut -d '\"' -f 4 \\ | wget -qi - Unzip tar file sudo tar xvf source-to-image*.gz Make s2i CLI accessiblee. sudo mv s2i /usr/local/bin verify s2i version With that done, you can start the lab.","title":"Source-to-Image (S2I)"},{"location":"references/CONTRIBUTORS/","text":"Contributors \u00b6 Remko de Knikker, github , Steve Martinelli, github , John Zaccone, github ,","title":"Contributors"},{"location":"references/CONTRIBUTORS/#contributors","text":"Remko de Knikker, github , Steve Martinelli, github , John Zaccone, github ,","title":"Contributors"},{"location":"references/RESOURCES/","text":"Additional resources \u00b6 IBM Demos \u00b6 Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage Redbooks \u00b6 IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices Videos \u00b6 Video: Postal codes and part numbers (DataStage) Video: Calculate employee compensation (read from CSV) (DataStage and Gov. Catalog) Video: Banks have merged (DataStage and Gov. Catalog) Video: Groceries with Kafka (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Additional Resources"},{"location":"references/RESOURCES/#additional-resources","text":"","title":"Additional resources"},{"location":"references/RESOURCES/#ibm-demos","text":"Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage","title":"IBM Demos"},{"location":"references/RESOURCES/#redbooks","text":"IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices","title":"Redbooks"},{"location":"references/RESOURCES/#videos","text":"Video: Postal codes and part numbers (DataStage) Video: Calculate employee compensation (read from CSV) (DataStage and Gov. Catalog) Video: Banks have merged (DataStage and Gov. Catalog) Video: Groceries with Kafka (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Videos"}]}